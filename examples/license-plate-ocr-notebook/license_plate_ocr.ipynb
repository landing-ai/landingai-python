{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License Plate Detection and OCR Processing\n",
    "\n",
    "## Table of Contents\n",
    "1. [Frame Extraction](#frame-extraction)\n",
    "2. [License Plate Detection](#license-plate-detection)\n",
    "3. [Image Cropping](#image-cropping)\n",
    "4. [OCR and Data Retrieval](#ocr-and-data-retrieval)\n",
    "\n",
    "In this Jupyter notebook, we guide you through a comprehensive process of building a computer vision application with LandingLens focused on detecting and reading license plates from videos. Starting with frame extraction, followed by the detection and cropping of license plates, and finally, Optical Character Recognition (OCR) for data retrieval, each section is crafted to provide you with a conceptual understanding and practical code examples. By the end of this notebook, not only will you have a functioning license plate reader, but you'll also possess foundational knowledge and techniques that are transferable to a myriad of other computer vision applications. Whether you're aiming to recognize faces, track objects, or read text from images, the principles and methods showcased here will serve as a valuable cornerstone for your future projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation and setup\n",
    "\n",
    "1. Install the `landingai` python package.\n",
    "2. We prepared a video clip with license plates from different cars on a street. We need to download the video clip to local.\n",
    "\n",
    "The video file will be downloaded at `/tmp/license-plates.mov`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install landingai gdown\n",
    "\n",
    "!gdown \"https://drive.google.com/uc?id=16iwE7mcz9zHqKCw2ilx0QEwSCjDdXEW4\" -O /tmp/license-plates.mov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"frame-extraction\"></a>\n",
    "## Frame Extraction\n",
    "\n",
    "In this section, we'll be extracting frames from a given video file. By reading the video frame-by-frame, we aim to save specific frames based on a set interval (e.g., every 100th frame) for further processing. This approach helps in reducing the computational load by processing only a subset of the frames instead of every single one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "Video(\"https://drive.google.com/uc?export=view&id=16iwE7mcz9zHqKCw2ilx0QEwSCjDdXEW4\", width=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from landingai.pipeline.image_source import VideoFile\n",
    "\n",
    "# Replace 'path_to_video_file' with the actual path to your video file\n",
    "# video_file_path = '/Users/whit_blodgett/Desktop/Code/landing-apps-poc/license_plate_ocr_app/IMG_2464.MOV'\n",
    "video_file_path = \"/tmp/license-plates.mov\"\n",
    "\n",
    "video_source = VideoFile(video_file_path, samples_per_second=1)\n",
    "frames = [f.frames[0].image for f in video_source]\n",
    "print(f\"Extracted {len(frames)} frames from the above video\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"license-plate-detection\"></a>\n",
    "\n",
    "## License Plate Detection\n",
    "Once we have our frames, the next step is to detect license plates within these frames. We'll be using a predefined API to help us detect the bounding boxes around the license plates. The results will be overlayed on the frames to visualize the detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from landingai.postprocess import crop\n",
    "from landingai.predict import Predictor\n",
    "from landingai import visualize\n",
    "\n",
    "def detect_license_plates(frames):\n",
    "    bounding_boxes = []\n",
    "    overlayed_frames = []\n",
    "    api_key = \"land_sk_aMemWbpd41yXnQ0tXvZMh59ISgRuKNRKjJEIUHnkiH32NBJAwf\"\n",
    "    model_endpoint = \"e001c156-5de0-43f3-9991-f19699b31202\"\n",
    "    predictor = Predictor(model_endpoint, api_key=api_key)\n",
    "\n",
    "    for frame in frames:\n",
    "        prediction = predictor.predict(frame)\n",
    "        # store predictions in a list\n",
    "        overlay = visualize.overlay_predictions(prediction, frame)\n",
    "        bounding_boxes.append(prediction)\n",
    "        overlayed_frames.append(overlay)\n",
    "\n",
    "    return bounding_boxes, overlayed_frames\n",
    "\n",
    "bounding_boxes, overlayed_frames = detect_license_plates(frames)\n",
    "\n",
    "# show 5 overlayed frames\n",
    "for i, frame in enumerate(overlayed_frames):\n",
    "    if len(bounding_boxes[i]) == 0:\n",
    "        continue\n",
    "    display(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"image-cropping\"></a>\n",
    "\n",
    "## Image Cropping\n",
    "With the detected bounding boxes, we'll be cropping the original images to isolate the license plates. This is crucial for ensuring the OCR model can read the license plate numbers and letters without unnecessary distractions from the surrounding scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from landingai.postprocess import crop\n",
    "\n",
    "# cropping the license plate\n",
    "cropped_imgs = []\n",
    "for frame, bboxes in zip(frames, bounding_boxes):\n",
    "    cropped_imgs.append(crop(bboxes, frame))\n",
    "\n",
    "print(len(cropped_imgs))\n",
    "# show 5 overlayed frames\n",
    "for i, cropped in enumerate(cropped_imgs):\n",
    "    if len(cropped) == 0:\n",
    "        continue\n",
    "    for plate in cropped:\n",
    "        display(plate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ocr-and-data-retrieval\"></a>\n",
    "\n",
    "## OCR and Data Retrieval\n",
    "In this section, we'll pass the cropped license plate images through an Optical Character Recognition (OCR) model. The OCR model's job is to convert the image of the license plate into a string of text, allowing us to retrieve the license plate number.\n",
    "\n",
    "> **PREREQUISITE**: You need to set your API key in below cell in order to use the OCR function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from landingai.predict import OcrPredictor\n",
    "import PIL.Image\n",
    "\n",
    "# TODO: set your OCR API key \n",
    "API_KEY = \"\"\n",
    "ocr_predictor = OcrPredictor(api_key=API_KEY)\n",
    "\n",
    "ocr_preds = []\n",
    "overlayed_ocr = []\n",
    "print(cropped_imgs[0])\n",
    "for frame in cropped_imgs:\n",
    "    for plate in frame:\n",
    "        ocr_pred = ocr_predictor.predict(plate)\n",
    "        ocr_preds.append(ocr_pred)\n",
    "        overlay = visualize.overlay_predictions(ocr_pred, plate)\n",
    "        overlayed_ocr.append(overlay)\n",
    "print(ocr_preds)\n",
    "for frame, ocr_pred in zip(overlayed_ocr, ocr_preds):\n",
    "    if len(ocr_pred) == 0:\n",
    "        continue\n",
    "    display(frame)\n",
    "    for text in ocr_pred:\n",
    "        print(text.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Businesses can leverage this technology for enhanced parking lot management, toll collection, or even monitoring customer inflow in commercial areas. By harnessing the power of this system, stakeholders can drive operational efficiency, enhanced security, and ultimately, deliver tangible value across multiple domains."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
